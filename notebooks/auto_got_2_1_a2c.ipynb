{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Automated Graph of Thoughts - A2C Model Experiments",
   "id": "e37ee4a5b87f9c4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:02:40.925099Z",
     "start_time": "2024-05-09T10:02:40.142176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from auto_graph_of_thoughts.env import GraphObservationComponent, GraphStepRewardVersion\n",
    "from auto_graph_of_thoughts.experiment import ExperimentConfiguration, LanguageModelSimulationType, Experiment\n",
    "from auto_graph_of_thoughts.tasks.sum_list import sum_list_task\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "ENABLE_TRAINING = True\n",
    "ENABLE_EVALUATION = True\n",
    "\n",
    "N_VEC_ENVS = 8\n",
    "\n",
    "TRAIN_COMPLEXITIES = [c for c in range(1, 32 + 1)]\n",
    "EVAL_COMPLEXITIES = [c for c in range(1, 64 + 1)]\n",
    "\n",
    "EVAL_N_EPISODES = 100\n",
    "\n",
    "config = ExperimentConfiguration(\n",
    "        seed=SEED,\n",
    "        task=sum_list_task,\n",
    "        max_steps=20,\n",
    "        observation_filter={\n",
    "            GraphObservationComponent.depth,\n",
    "            GraphObservationComponent.breadth,\n",
    "            GraphObservationComponent.complexity,\n",
    "            GraphObservationComponent.prev_actions,\n",
    "            GraphObservationComponent.graph_operations,\n",
    "            GraphObservationComponent.local_complexity,\n",
    "            GraphObservationComponent.prev_score\n",
    "        },\n",
    "        max_depth=8,\n",
    "        max_breadth=8,\n",
    "        divergence_cutoff_factor=0.5,\n",
    "        train_complexities=TRAIN_COMPLEXITIES,\n",
    "        eval_complexities=EVAL_COMPLEXITIES,\n",
    "        max_complexity=max(EVAL_COMPLEXITIES),\n",
    "        max_operations=32,\n",
    "        lm_simulation_type=LanguageModelSimulationType.REALISTIC,\n",
    "        reward_version=GraphStepRewardVersion.V4\n",
    ")\n",
    "experiment = Experiment(config)"
   ],
   "id": "ab926f74fe9a63d9",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Utilities",
   "id": "e46d8c2383069096"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:02:40.933699Z",
     "start_time": "2024-05-09T10:02:40.926115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pure_graph_of_thoughts.api.schema import JsonSchemaEncoder\n",
    "import json\n",
    "import os\n",
    "from auto_graph_of_thoughts.experiment.agent_evaluation_summary import AgentEvaluationSummary\n",
    "\n",
    "results_directory = './artifacts/results/agent_evaluations'\n",
    "\n",
    "def store_evaluation_summary(evaluation_summary: AgentEvaluationSummary) -> None:\n",
    "    \"\"\"\n",
    "    Stores an evaluation summary to file.\n",
    "    :param evaluation_summary: evaluation summary to store\n",
    "    \"\"\"\n",
    "    file_name = f'{results_directory}/{evaluation_summary.name}.json'\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        json.dump(evaluation_summary, f, cls=JsonSchemaEncoder, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_evaluation_summary(name: str) -> AgentEvaluationSummary:\n",
    "    \"\"\"\n",
    "    Loads an evaluation summary.\n",
    "    :param name: name\n",
    "    :return: loaded evaluation summary\n",
    "    \"\"\"\n",
    "    file_name = f'{results_directory}/{name}.json'\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        return AgentEvaluationSummary.from_dict(json.load(f))"
   ],
   "id": "a877f7a86c581dd",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:02:41.391926Z",
     "start_time": "2024-05-09T10:02:40.934704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Mapping\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "COLOR_VALID = '#6acc64'\n",
    "def visualize_solved_rate(name: str, solved_rate: Mapping[int, float]) -> None:\n",
    "    df = pd.DataFrame(list(solved_rate.items()), columns=['cardinality', 'solved_rate'])\n",
    "    fig = px.bar(\n",
    "            df,\n",
    "            x='cardinality',\n",
    "            y='solved_rate',\n",
    "            title=f'Agent Evaluation Results for {name}',\n",
    "            template='simple_white',\n",
    "            labels={\n",
    "                'cardinality': 'list cardinality',\n",
    "                'solved_rate': 'solved tasks rate'\n",
    "            },\n",
    "            height=400\n",
    "    )\n",
    "    fig.update_xaxes(dtick=1)\n",
    "    fig.update_traces(marker_color=COLOR_VALID)\n",
    "    fig.show()"
   ],
   "id": "78a567c3e88be034",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Default Network Architecture",
   "id": "d0993d72c5120b7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:02:41.397068Z",
     "start_time": "2024-05-09T10:02:41.392931Z"
    }
   },
   "cell_type": "code",
   "source": "model_a2c_name_default = 'a2c_r4_64x64_c1to32_t2xx18_lrfix'",
   "id": "ec30f91144e281d7",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train",
   "id": "a89f0c3d42e64cf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:41.173450Z",
     "start_time": "2024-05-09T10:02:41.398073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "vec_env = make_vec_env(experiment.create_filtered_train_env, n_envs=N_VEC_ENVS)\n",
    "policy_kwargs = dict(\n",
    "        net_arch=[64, 64]\n",
    ")\n",
    "model_a2c_default = A2C(\n",
    "        'MultiInputPolicy',\n",
    "        vec_env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=1,\n",
    "        tensorboard_log='./artifacts/tensorboard'\n",
    ")\n",
    "if ENABLE_TRAINING:\n",
    "    model_a2c_default.learn(total_timesteps=2 ** 18, tb_log_name=model_a2c_name_default)\n",
    "    mean_reward, std_reward = evaluate_policy(model_a2c_default, model_a2c_default.get_env(), n_eval_episodes=EVAL_N_EPISODES)\n",
    "    print(f\"Mean reward: {mean_reward} +/- {std_reward}\")\n",
    "    model_a2c_default.save(f'./artifacts/models/{model_a2c_name_default}')"
   ],
   "id": "d07555177251ebc1",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate",
   "id": "b5b694e50810d65e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:41.209192Z",
     "start_time": "2024-05-09T10:08:41.173450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import A2C\n",
    "model_a2c_default = A2C.load(f'./artifacts/models/{model_a2c_name_default}')"
   ],
   "id": "75a6aeae08ce0887",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:41.743714Z",
     "start_time": "2024-05-09T10:08:41.209192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env, filtered_env  = experiment.created_eval_env_tuple()\n",
    "obs, info = filtered_env.reset()\n",
    "print(f'Complexity: {env.local_complexity}')\n",
    "for i in range(100):\n",
    "    action, _states = model_a2c_default.predict(obs)\n",
    "    decoded_action = env.decode_action(action)\n",
    "    obs, rewards, terminated, truncated, info = filtered_env.step(action)\n",
    "    local_complexity = env.local_complexity\n",
    "    print(f'local complexity: {local_complexity} action: {decoded_action.type.name}-{decoded_action.operation.name if decoded_action.operation is not None else None} = {float(rewards)}')\n",
    "    if terminated or truncated:\n",
    "        obs, info = filtered_env.reset()\n",
    "        print(f'Complexity: {env.local_complexity}')"
   ],
   "id": "bba45906f41e18bb",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:11:15.597041Z",
     "start_time": "2024-05-09T10:08:41.743714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from auto_graph_of_thoughts.experiment.evaluate_agent import evaluate_agent\n",
    "\n",
    "if ENABLE_EVALUATION:\n",
    "    evaluation_a2c = evaluate_agent(\n",
    "            experiment,\n",
    "            model_a2c_name_default,\n",
    "            EVAL_N_EPISODES,\n",
    "            lambda obs: model_a2c_default.predict(obs)[0]\n",
    "    )\n",
    "    store_evaluation_summary(evaluation_a2c.summary)\n",
    "\n",
    "evaluation_a2c_summary = load_evaluation_summary(model_a2c_name_default)\n",
    "evaluation_a2c_summary.solved_rate_train_complexities, evaluation_a2c_summary.solved_rate_eval_complexities"
   ],
   "id": "55f9d99baffce2a1",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:11:16.069033Z",
     "start_time": "2024-05-09T10:11:15.597041Z"
    }
   },
   "cell_type": "code",
   "source": "visualize_solved_rate(model_a2c_name_default, evaluation_a2c_summary.solved_rate_per_complexity)",
   "id": "b163994c78f1bdc4",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Network Architecture 32x32",
   "id": "75df246cce75a645"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_a2c_name_32x32 = 'a2c_r4_32x32_c1to32_t2xx18_lrfix'",
   "id": "af9aff8620fb06f",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train",
   "id": "ca6eb4371ddcf3ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:19:39.216216Z",
     "start_time": "2024-05-09T10:11:16.074402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "vec_env = make_vec_env(experiment.create_filtered_train_env, n_envs=N_VEC_ENVS)\n",
    "policy_kwargs = dict(\n",
    "        net_arch=[32, 32]\n",
    ")\n",
    "model_a2c_32x32 = A2C(\n",
    "        'MultiInputPolicy',\n",
    "        vec_env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=1,\n",
    "        tensorboard_log='./artifacts/tensorboard'\n",
    ")\n",
    "\n",
    "if ENABLE_TRAINING:\n",
    "    model_a2c_32x32.learn(total_timesteps=2 ** 18, tb_log_name=model_a2c_name_32x32)\n",
    "    mean_reward, std_reward = evaluate_policy(model_a2c_32x32, model_a2c_32x32.get_env(), n_eval_episodes=EVAL_N_EPISODES)\n",
    "    print(f'Mean reward: {mean_reward} +/- {std_reward}')\n",
    "    model_a2c_32x32.save(f'./artifacts/models/{model_a2c_name_32x32}')"
   ],
   "id": "initial_id",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate",
   "id": "8985771279e95acb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:19:39.251879Z",
     "start_time": "2024-05-09T10:19:39.216216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import A2C\n",
    "model_a2c_32x32 = A2C.load(f'./artifacts/models/{model_a2c_name_32x32}')"
   ],
   "id": "818a11aaaaa77b",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:19:39.783507Z",
     "start_time": "2024-05-09T10:19:39.251879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env, filtered_env  = experiment.created_eval_env_tuple()\n",
    "obs, info = filtered_env.reset()\n",
    "print(f'Complexity: {env.local_complexity}')\n",
    "for i in range(100):\n",
    "    action, _states = model_a2c_32x32.predict(obs)\n",
    "    decoded_action = env.decode_action(action)\n",
    "    obs, rewards, terminated, truncated, info = filtered_env.step(action)\n",
    "    local_complexity = env.local_complexity\n",
    "    print(f'local complexity: {local_complexity} action: {decoded_action.type.name}-{decoded_action.operation.name if decoded_action.operation is not None else None} = {float(rewards)}')\n",
    "    if terminated or truncated:\n",
    "        obs, info = filtered_env.reset()\n",
    "        print(f'Complexity: {env.local_complexity}')"
   ],
   "id": "3cef1566c7a1528",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:23:52.802165Z",
     "start_time": "2024-05-09T10:19:39.783507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from auto_graph_of_thoughts.experiment.evaluate_agent import evaluate_agent\n",
    "\n",
    "if ENABLE_EVALUATION:\n",
    "    evaluation_a2c_32x32 = evaluate_agent(\n",
    "            experiment,\n",
    "            model_a2c_name_32x32,\n",
    "            EVAL_N_EPISODES,\n",
    "            lambda obs: model_a2c_32x32.predict(obs)[0]\n",
    "    )\n",
    "    store_evaluation_summary(evaluation_a2c_32x32.summary)\n",
    "evaluation_a2c_32x32_summary = load_evaluation_summary(model_a2c_name_32x32)\n",
    "evaluation_a2c_32x32_summary.solved_rate_train_complexities, evaluation_a2c_32x32_summary.solved_rate_eval_complexities"
   ],
   "id": "c62f7f8f500bba6e",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:23:52.846295Z",
     "start_time": "2024-05-09T10:23:52.802165Z"
    }
   },
   "cell_type": "code",
   "source": "visualize_solved_rate(model_a2c_name_32x32, evaluation_a2c_32x32_summary.solved_rate_per_complexity)",
   "id": "88eaa3d6ff64269",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Learning Rate Decrease",
   "id": "a93ddf5875dd6fc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:23:52.850896Z",
     "start_time": "2024-05-09T10:23:52.846295Z"
    }
   },
   "cell_type": "code",
   "source": "model_a2c_name_lrlin = 'a2c_r4_64x64_c1to32_t2xx18_lrlin'",
   "id": "97ca73eab352882a",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train",
   "id": "6a2b9675e7078653"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:23:52.859118Z",
     "start_time": "2024-05-09T10:23:52.850896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Callable\n",
    "\n",
    "def learning_rate_linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    return lambda progress_remaining: initial_value * progress_remaining"
   ],
   "id": "97c23c484bbd345c",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:29:51.107409Z",
     "start_time": "2024-05-09T10:23:52.859118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "vec_env = make_vec_env(experiment.create_filtered_train_env, n_envs=N_VEC_ENVS)\n",
    "policy_kwargs = dict(\n",
    "        net_arch=[64, 64]\n",
    ")\n",
    "model_a2c_lrlin = A2C(\n",
    "        'MultiInputPolicy',\n",
    "        vec_env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=1,\n",
    "        learning_rate=learning_rate_linear_schedule(0.01),\n",
    "        tensorboard_log='./artifacts/tensorboard'\n",
    ")\n",
    "if ENABLE_TRAINING:\n",
    "    model_a2c_lrlin.learn(total_timesteps=2 ** 18, tb_log_name=model_a2c_name_lrlin)\n",
    "    mean_reward, std_reward = evaluate_policy(model_a2c_lrlin, model_a2c_lrlin.get_env(), n_eval_episodes=EVAL_N_EPISODES)\n",
    "    print(f'Mean reward: {mean_reward} +/- {std_reward}')\n",
    "    model_a2c_lrlin.save(f'./artifacts/models/{model_a2c_name_lrlin}')"
   ],
   "id": "cca3f7008f31a9ef",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:29:51.595368Z",
     "start_time": "2024-05-09T10:29:51.107409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env, filtered_env  = experiment.created_eval_env_tuple()\n",
    "obs, info = filtered_env.reset()\n",
    "print(f'Complexity: {env.local_complexity}')\n",
    "for i in range(100):\n",
    "    action, _states = model_a2c_lrlin.predict(obs)\n",
    "    decoded_action = env.decode_action(action)\n",
    "    obs, rewards, terminated, truncated, info = filtered_env.step(action)\n",
    "    local_complexity = env.local_complexity\n",
    "    print(f'local complexity: {local_complexity} action: {decoded_action.type.name}-{decoded_action.operation.name if decoded_action.operation is not None else None} = {float(rewards)}')\n",
    "    if terminated or truncated:\n",
    "        obs, info = filtered_env.reset()\n",
    "        print(f'Complexity: {env.local_complexity}')"
   ],
   "id": "969d4913ec368cb5",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate",
   "id": "9bc46c423254c4dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:29:51.625408Z",
     "start_time": "2024-05-09T10:29:51.595368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import A2C\n",
    "model_a2c_lrlin = A2C.load(f'./artifacts/models/{model_a2c_name_lrlin}')"
   ],
   "id": "d04c74de5e54b5e7",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:37:21.348269Z",
     "start_time": "2024-05-09T10:29:51.625408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from auto_graph_of_thoughts.experiment.evaluate_agent import evaluate_agent\n",
    "\n",
    "if ENABLE_EVALUATION:\n",
    "    evaluation_a2c_lrlin = evaluate_agent(\n",
    "            experiment,\n",
    "            model_a2c_name_lrlin,\n",
    "            EVAL_N_EPISODES,\n",
    "            lambda obs: model_a2c_lrlin.predict(obs)[0]\n",
    "    )\n",
    "    store_evaluation_summary(evaluation_a2c_lrlin.summary)\n",
    "evaluation_a2c_lrlin_summary = load_evaluation_summary(model_a2c_name_lrlin)\n",
    "evaluation_a2c_lrlin_summary.solved_rate_train_complexities, evaluation_a2c_lrlin_summary.solved_rate_eval_complexities"
   ],
   "id": "9f160ba0b137fae0",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:37:21.391573Z",
     "start_time": "2024-05-09T10:37:21.348269Z"
    }
   },
   "cell_type": "code",
   "source": "visualize_solved_rate(model_a2c_name_lrlin, evaluation_a2c_lrlin_summary.solved_rate_per_complexity)",
   "id": "5d5b1d280fb464d2",
   "execution_count": 22,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
